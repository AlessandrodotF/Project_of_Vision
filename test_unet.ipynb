{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8937bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch functions\n",
    "import torch\n",
    "# Neural network layers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "# Handling dataset|\n",
    "import torch.utils.data as data\n",
    "# Torchvision library\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "# For results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from MountainDataset import MountainDataset\n",
    "# check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.is_available())\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b988d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aaabb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./dataset\"\n",
    "train_data = MountainDataset(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdef2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mountain Data Set\n",
      "Root directory: {self.rootDir}Length 24049\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8ffb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data Normalization should be done Previously. Saves Startup time\n",
    "def create_validation_set(train_data, train_percentage, test_transforms = None):\n",
    "\n",
    "    \n",
    "    n_train_examples = int(len(train_data) * train_percentage)\n",
    "    n_valid_examples = len(train_data) - n_train_examples\n",
    "    \n",
    "     # Create 'Subset' objects\n",
    "    train_data, valid_data = data.random_split(train_data, [n_train_examples, n_valid_examples])\n",
    "\n",
    "    print(f\"Number training examples: {len(train_data)}\")\n",
    "    print(f\"Number validation examples: {len(valid_data)}\")\n",
    "\n",
    "    # Apply test transformations to the validation set\n",
    "    valid_data = copy.deepcopy(valid_data) # If we change train transformations, this won't affect the validation set\n",
    "    valid_data.dataset.transform = test_transforms\n",
    "\n",
    "    return valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d92a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number training examples: 19239\n",
      "Number validation examples: 4810\n"
     ]
    }
   ],
   "source": [
    "valid_data = create_validation_set(train_data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320be15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterators\n",
    "#TODO: Maybe change batch Size to 32 if memory runs out\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iterator = torch.utils.data.DataLoader(train_data, \n",
    "                                             shuffle=True, \n",
    "                                             batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = torch.utils.data.DataLoader(valid_data, \n",
    "                                             batch_size=BATCH_SIZE)\n",
    "\n",
    "#test_iterator = torch.utils.data.DataLoader(test_data, \n",
    "#                                            batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b357e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_online import UNet\n",
    "model = UNet(1, 1, bilinear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c01ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,864,257 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59119bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo look more into the Criterion for now Softmax + Crossentropy sounds good\n",
    "# Loss\n",
    "# Crossentropy works only with multiple classes -> use BCEwith logitsloss instead\n",
    "#criterion = nn.CrossEntropyLoss() # Softmax + CrossEntropy\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# Put model&criterion on GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8623f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optim\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)#, momentum=0.99)\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, weight_decay=1e-8, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e5d7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  # Train mode\n",
    "  model.train()\n",
    "  \n",
    "  for (x,y) in iterator:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    # Set gradients to zero\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Make Predictions\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = calculate_accuracy(y_pred, y, BATCH_SIZE)\n",
    "\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # Apply optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Extract data from loss and accuracy\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "  #print(f\"epoch_acc:{epoch_acc/len(iterator)} , len: {len(iterator)}\")\n",
    "  return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c009245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  # Evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Do not compute gradients\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for(x,y) in iterator:\n",
    "\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "      \n",
    "      # Make Predictions\n",
    "      y_pred = model(x)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(y_pred, y)\n",
    "      \n",
    "      for i in range(2):\n",
    "        plot_img(y_pred[i,0], y[i,0])\n",
    "      # Compute accuracy\n",
    "      acc = calculate_accuracy(y_pred, y, BATCH_SIZE)\n",
    "\n",
    "      # Extract data from loss and accuracy\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "\n",
    "  return epoch_loss/len(iterator), epoch_acc/len(iterator)\n",
    "\n",
    "def plot_img(im1, im2):\n",
    "  fig = plt.figure(figsize=(20,10))\n",
    "  gs = fig.add_gridspec(1,2, hspace=0)\n",
    "  (ax1, ax2) = gs.subplots()\n",
    "  ax1.imshow(im1)\n",
    "  ax2.imshow(im2)\n",
    "  #cbar_ax = fig.add_axes([0,0, im1.size()[0], im1.size()[1]])\n",
    "  #fig.subplots_adjust(right=0.8)\n",
    "  #fig.colorbar(im2.detach().numpy(), cax=cbar_ax)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b1c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred, mask):\n",
    "    compare= np.equal(pred.detach().numpy(), mask.detach().numpy())\n",
    "    accuracy = np.sum(compare)\n",
    "    return accuracy/len(pred.flatten())\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_pred, y, batch_size):\n",
    "    '''\n",
    "    Compute accuracy from ground-truth and predicted labels.\n",
    "    \n",
    "    Input\n",
    "    ------\n",
    "    y_pred: torch.Tensor [BATCH_SIZE, N_LABELS]\n",
    "    y: torch.Tensor [BATCH_SIZE]\n",
    "  \n",
    "    Output\n",
    "    ------\n",
    "    acc: float\n",
    "      Accuracy\n",
    "    '''\n",
    "    batch_size= min(y.shape[0], batch_size)\n",
    "    total_acc = 0\n",
    "    for i in range(batch_size):\n",
    "        total_acc += acc(y_pred[i], y[i])\n",
    "    \n",
    "    \n",
    "    return total_acc/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb1cb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(n_epochs, model, train_iterator, valid_iterator, optimizer, criterion, device, model_name='best_model.pt'):\n",
    "\n",
    "  # Initialize validation loss\n",
    "  best_valid_loss = float('inf')\n",
    "\n",
    "  # Save output losses, accs\n",
    "  train_losses = []\n",
    "  train_accs = []\n",
    "  valid_losses = []\n",
    "  valid_accs = []\n",
    "\n",
    "  # Loop over epochs\n",
    "  for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Train\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    # Validation\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "    # Save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "      best_valid_loss = valid_loss\n",
    "      # Save model\n",
    "      torch.save(model.state_dict(), model_name)\n",
    "      model.save_model(model_name)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch: {epoch+1}/{n_epochs} -- Epoch Time: {end_time-start_time:.2f} s\")\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"Train -- Loss: {train_loss:.3f}, Acc: {train_acc * 100:.2f}%\")\n",
    "    print(f\"Val -- Loss: {valid_loss:.3f}, Acc: {valid_acc * 100:.2f}%\")\n",
    "\n",
    "    # Save\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accs.append(valid_acc)\n",
    "\n",
    "  return train_losses, train_accs, valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dac28ea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 200, 200] at entry 0 and [1, 200, 160] at entry 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-25ac7ff95e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_losses, train_accs, valid_losses, valid_accs = model_training(N_EPOCHS, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                     \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                     \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1a6bcb8d0691>\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m(n_epochs, model, train_iterator, valid_iterator, optimizer, criterion, device, model_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-f698fac20d3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vision-course/conda_vision/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vision-course/conda_vision/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vision-course/conda_vision/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/vision-course/conda_vision/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vision-course/conda_vision/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vision-course/conda_vision/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vision-course/conda_vision/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 200, 200] at entry 0 and [1, 200, 160] at entry 9"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 4\n",
    "train_losses, train_accs, valid_losses, valid_accs = model_training(N_EPOCHS, \n",
    "                                                                    model, \n",
    "                                                                    train_iterator, \n",
    "                                                                    valid_iterator, \n",
    "                                                                    optimizer, \n",
    "                                                                    criterion, \n",
    "                                                                    device,\n",
    "                                                                    'unet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866872bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n_epochs, train_losses, train_accs, valid_losses, valid_accs):\n",
    "  N_EPOCHS = n_epochs\n",
    "  # Plot results\n",
    "  plt.figure(figsize=(20, 6))\n",
    "  _ = plt.subplot(1,2,1)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, train_losses, linewidth=3)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, valid_losses, linewidth=3)\n",
    "  _ = plt.legend(['Train', 'Validation'])\n",
    "  plt.grid('on'), plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "\n",
    "  _ = plt.subplot(1,2,2)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, train_accs, linewidth=3)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, valid_accs, linewidth=3)\n",
    "  _ = plt.legend(['Train', 'Validation'])\n",
    "  plt.grid('on'), plt.xlabel('Epoch'), plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(N_EPOCHS, train_losses, train_accs, valid_losses, valid_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = \"./TODO\"\n",
    "model.save_model(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadPath = savepath\n",
    "model = torch.load(loadPath)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0028e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda-Vision",
   "language": "python",
   "name": "conda-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
