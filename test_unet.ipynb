{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bcbbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch functions\n",
    "import torch\n",
    "# Neural network layers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "# Handling dataset|\n",
    "import torch.utils.data as data\n",
    "# Torchvision library\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "# For results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from MountainDataset import MountainDataset\n",
    "# check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.is_available())\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10dfca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2819ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./dataset\"\n",
    "train_data = MountainDataset(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e492e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mountain Data Set\n",
      "Root directory: {self.rootDir}Length 931\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ebbcbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Data Normalization should be done Previously. Saves Startup time\n",
    "def create_validation_set(train_data, train_percentage, test_transforms = None):\n",
    "\n",
    "    \n",
    "    n_train_examples = int(len(train_data) * train_percentage)\n",
    "    n_valid_examples = len(train_data) - n_train_examples\n",
    "    \n",
    "     # Create 'Subset' objects\n",
    "    train_data, valid_data = data.random_split(train_data, [n_train_examples, n_valid_examples])\n",
    "\n",
    "    print(f\"Number training examples: {len(train_data)}\")\n",
    "    print(f\"Number validation examples: {len(valid_data)}\")\n",
    "\n",
    "    # Apply test transformations to the validation set\n",
    "    valid_data = copy.deepcopy(valid_data) # If we change train transformations, this won't affect the validation set\n",
    "    valid_data.dataset.transform = test_transforms\n",
    "\n",
    "    return valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed9681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number training examples: 744\n",
      "Number validation examples: 187\n"
     ]
    }
   ],
   "source": [
    "valid_data = create_validation_set(train_data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b40e3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterators\n",
    "#TODO: Maybe change batch Size to 32 if memory runs out\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator = torch.utils.data.DataLoader(train_data, \n",
    "                                             shuffle=True, \n",
    "                                             batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = torch.utils.data.DataLoader(valid_data, \n",
    "                                             batch_size=BATCH_SIZE)\n",
    "\n",
    "#test_iterator = torch.utils.data.DataLoader(test_data, \n",
    "#                                            batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8125faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import UNet\n",
    "model = UNet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "908ac090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,697,665 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "831d3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo look more into the Criterion for now Softmax + Crossentropy sounds good\n",
    "# Loss\n",
    "# Crossentropy works only with multiple classes -> use BCEwith logitsloss instead\n",
    "#criterion = nn.CrossEntropyLoss() # Softmax + CrossEntropy\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# Put model&criterion on GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03e2c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=5e-4)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "283fae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  # Train mode\n",
    "  model.train()\n",
    "\n",
    "  for (x,y) in iterator:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    # Set gradients to zero\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Make Predictions\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # Apply optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Extract data from loss and accuracy\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "\n",
    "  return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56230e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  # Evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Do not compute gradients\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for(x,y) in iterator:\n",
    "\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "      \n",
    "      # Make Predictions\n",
    "      y_pred = model(x)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(y_pred, y)\n",
    "      \n",
    "      # Compute accuracy\n",
    "      acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "      # Extract data from loss and accuracy\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "\n",
    "  return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e928201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "  '''\n",
    "  Compute accuracy from ground-truth and predicted labels.\n",
    "  \n",
    "  Input\n",
    "  ------\n",
    "  y_pred: torch.Tensor [BATCH_SIZE, N_LABELS]\n",
    "  y: torch.Tensor [BATCH_SIZE]\n",
    "\n",
    "  Output\n",
    "  ------\n",
    "  acc: float\n",
    "    Accuracy\n",
    "  '''\n",
    "  y_prob = F.softmax(y_pred, dim = -1)\n",
    "  y_pred = y_pred.argmax(dim=1, keepdim = True)\n",
    "  correct = y_pred.eq(y.view_as(y_pred)).sum()\n",
    "  acc = correct.float()/y.shape[0]\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67541415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(n_epochs, model, train_iterator, valid_iterator, optimizer, criterion, device, model_name='best_model.pt'):\n",
    "\n",
    "  # Initialize validation loss\n",
    "  best_valid_loss = float('inf')\n",
    "\n",
    "  # Save output losses, accs\n",
    "  train_losses = []\n",
    "  train_accs = []\n",
    "  valid_losses = []\n",
    "  valid_accs = []\n",
    "\n",
    "  # Loop over epochs\n",
    "  for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Train\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    # Validation\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "    # Save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "      best_valid_loss = valid_loss\n",
    "      # Save model\n",
    "      torch.save(model.state_dict(), model_name)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch: {epoch+1}/{n_epochs} -- Epoch Time: {end_time-start_time:.2f} s\")\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"Train -- Loss: {train_loss:.3f}, Acc: {train_acc * 100:.2f}%\")\n",
    "    print(f\"Val -- Loss: {valid_loss:.3f}, Acc: {valid_acc * 100:.2f}%\")\n",
    "\n",
    "    # Save\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accs.append(valid_acc)\n",
    "\n",
    "  return train_losses, train_accs, valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc802b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([3, 128, 94, 94]) torch.Size([3, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n",
      "torch.Size([27, 128, 94, 94]) torch.Size([27, 128, 86, 86])\n",
      "\n",
      "Epoch: 1/2 -- Epoch Time: 3233.88 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 2427344.38%\n",
      "Val -- Loss: 0.693, Acc: 2418555.47%\n",
      "torch.Size([32, 128, 94, 94]) torch.Size([32, 128, 86, 86])\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2\n",
    "train_losses, train_accs, valid_losses, valid_accs = model_training(N_EPOCHS, \n",
    "                                                                    model, \n",
    "                                                                    train_iterator, \n",
    "                                                                    valid_iterator, \n",
    "                                                                    optimizer, \n",
    "                                                                    criterion, \n",
    "                                                                    device,\n",
    "                                                                    'lenet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n_epochs, train_losses, train_accs, valid_losses, valid_accs):\n",
    "  N_EPOCHS = n_epochs\n",
    "  # Plot results\n",
    "  plt.figure(figsize=(20, 6))\n",
    "  _ = plt.subplot(1,2,1)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, train_losses, linewidth=3)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, valid_losses, linewidth=3)\n",
    "  _ = plt.legend(['Train', 'Validation'])\n",
    "  plt.grid('on'), plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "\n",
    "  _ = plt.subplot(1,2,2)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, train_accs, linewidth=3)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, valid_accs, linewidth=3)\n",
    "  _ = plt.legend(['Train', 'Validation'])\n",
    "  plt.grid('on'), plt.xlabel('Epoch'), plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df127f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(N_EPOCHS, train_losses, train_accs, valid_losses, valid_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = \"./TODO\"\n",
    "model.save_model(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af821fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadPath = savepath\n",
    "model = torch.load(loadPath)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda-Vision",
   "language": "python",
   "name": "conda-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
